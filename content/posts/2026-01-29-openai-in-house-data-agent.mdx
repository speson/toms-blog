---
title: "OpenAI 내부 데이터 에이전트: GPT-5, Codex, Memory로 데이터 분석 자동화"
description: "OpenAI가 자체 데이터 플랫폼을 위해 구축한 맞춤형 AI 데이터 에이전트. GPT-5, Codex, Embeddings API로 질문을 몇 분 만에 인사이트로 전환."
date: 2026-01-29
category: ai-news
tags: ["AI", "OpenAI", "데이터", "에이전트", "GPT-5", "Codex"]
source: openai
sourceUrl: "https://openai.com/index/inside-our-in-house-data-agent"
perspective: "개발자 관점: 앱 데이터 분석 자동화의 청사진"
handsOn: false
stackContext: ["react", "typescript", "sql", "analytics", "embeddings"]
tldrVerdict: "OpenAI의 내부 데이터 에이전트 아키텍처는 Embeddings API + RAG로 우리 앱의 분석 쿼리 자동화에도 적용 가능. 특히 복잡한 SQL 조인과 메타데이터 검색 문제를 해결하는 컨텍스트 레이어 설계가 인상적."
relevanceFrontend: "medium"
relevanceBackend: "high"
relevanceDevops: "low"
relevanceTooling: "high"
relevanceDatabase: "high"
---

OpenAI가 자체 플랫폼 데이터를 탐색하고 추론하는 **맞춤형 내부 AI 데이터 에이전트**를 구축했습니다. 이 에이전트는 외부 제공 서비스가 아닌 **OpenAI 내부 전용 도구**로, OpenAI의 데이터, 권한, 워크플로우에 특화되어 있습니다.

## 왜 맞춤형 도구가 필요했나

OpenAI의 데이터 플랫폼은 엔지니어링, 제품, 리서치를 아우르는 **3,500명 이상의 내부 사용자**에게 서비스를 제공하며, **600 페타바이트 이상의 데이터**와 **70,000개의 데이터셋**을 다룹니다.

이 규모에서는 **올바른 테이블을 찾는 것**만으로도 분석의 가장 시간 소모적인 부분이 됩니다.

> "유사한 테이블이 많아서 어떤 차이가 있고 어떤 걸 써야 하는지 파악하는 데 엄청난 시간을 씁니다. 일부는 로그아웃 사용자를 포함하고, 일부는 포함하지 않습니다. 필드가 겹치는 경우도 많아서 무엇이 무엇인지 구별하기 어렵습니다." - 내부 사용자

### 기존 문제점

- **테이블 검색의 어려움**: 70,000개 데이터셋 중 올바른 테이블 찾기
- **조인 오류**: Many-to-many 조인, 필터 푸시다운 오류, null 처리 미비
- **180줄 이상의 SQL**: 올바른 테이블과 컬럼으로 조인했는지 확인 어려움
- **분석 병목**: 데이터 과학자가 SQL 디버깅이 아닌 메트릭 정의와 의사결정에 집중해야 함

## 에이전트 작동 방식

### 접근 경로

에이전트는 직원들이 이미 작업하는 모든 곳에서 사용 가능합니다:

- **Slack 에이전트**
- **웹 인터페이스**
- **IDE 내부**
- **Codex CLI (MCP 통해)**
- **OpenAI 내부 ChatGPT 앱 (MCP 커넥터 통해)**

### 예시: NYC 택시 분석

사용자 질문:

> "NYC 택시 여행에서 어떤 승차-하차 ZIP 코드 쌍이 가장 불안정하며, 일반적인 경우와 최악의 경우 이동 시간 사이의 격차가 가장 크고, 그 변동성은 언제 발생하나요?"

에이전트는 **분석을 엔드투엔드로 처리**:

1. 질문 이해
2. 데이터 탐색
3. 쿼리 실행
4. 결과 종합

### 자가 학습 루프

에이전트의 강력한 기능 중 하나는 **문제를 추론하는 방식**입니다. 고정된 스크립트를 따르지 않고:

- 중간 결과 평가 (예: 잘못된 조인으로 인한 0행 결과)
- 문제 조사 및 접근 방식 조정
- 재시도
- **전체 컨텍스트 유지** 및 단계 간 학습 전달

이 **폐쇄 루프, 자가 학습 프로세스**는 반복을 사용자에서 에이전트로 이동시켜 더 빠른 결과와 일관되게 높은 품질의 분석을 제공합니다.

## 컨텍스트가 핵심

고품질 답변은 **풍부하고 정확한 컨텍스트**에 달려 있습니다. 컨텍스트 없이는 강력한 모델도 잘못된 결과를 생성할 수 있습니다.

### 컨텍스트의 6가지 레이어

#### Layer #1: 테이블 사용

- **메타데이터 기반**: 스키마 메타데이터 (컬럼명, 데이터 타입)
- **쿼리 추론**: 과거 쿼리 분석으로 SQL 작성 방식 학습
- **테이블 계보**: 업스트림/다운스트림 테이블 관계

#### Layer #2: 인간 주석

- 도메인 전문가가 제공한 **큐레이션된 설명**
- 비즈니스 의미, 알려진 주의사항 포함

#### Layer #3: Codex 보강

테이블의 **코드 레벨 정의**를 도출하여 더 깊은 이해 구축:

- 테이블에 저장된 내용과 분석 이벤트에서 파생되는 방식
- 값의 고유성, 업데이트 빈도, 데이터 범위 (예: 특정 필드 제외 여부)
- Spark, Python 등에서의 사용 방식

> 이를 통해 에이전트는 유사해 보이지만 중요한 방식으로 다른 테이블을 구별할 수 있습니다. 예: 테이블이 퍼스트파티 ChatGPT 트래픽만 포함하는지 여부

#### Layer #4: 조직 지식

- **Slack, Google Docs, Notion** 접근
- 출시, 신뢰성 사고, 내부 코드명 및 도구 포함
- 주요 메트릭의 정의와 계산 로직

#### Layer #5: Memory

에이전트가 수정사항이나 뉘앙스를 발견하면 **다음 사용을 위해 학습을 저장**:

- 반복적인 문제 방지
- 정확한 기준선에서 시작
- 전역 및 개인 수준으로 범위 지정
- 사용자가 수동으로 생성 및 편집 가능

#### Layer #6: 런타임 컨텍스트

- 테이블에 대한 이전 컨텍스트가 없거나 기존 정보가 오래된 경우 **데이터 웨어하우스에 라이브 쿼리 실행**
- 스키마 검증, 실시간 데이터 이해
- 메타데이터 서비스, Airflow, Spark 등 다른 데이터 플랫폼 시스템과 통신

### 컨텍스트 검색 파이프라인

1. **오프라인 전처리**: 테이블 사용, 인간 주석, Codex 보강을 단일 정규화된 표현으로 집계
2. **임베딩 생성**: [OpenAI Embeddings API](https://platform.openai.com/docs/api-reference/embeddings) 사용
3. **RAG 검색**: 쿼리 시점에 가장 관련성 높은 임베딩된 컨텍스트만 가져옴
4. **확장성**: 수만 개의 테이블에서도 빠르고 예측 가능한 레이턴시

## 팀원처럼 작동

에이전트는 **함께 추론할 수 있는 팀원처럼 작동**하도록 설계되었습니다:

- **대화형**: 항상 켜져 있으며 빠른 답변과 반복적 탐색 모두 처리
- **컨텍스트 유지**: 전체 컨텍스트를 턴 간에 전달하여 후속 질문, 의도 조정, 방향 전환 가능
- **중간 리디렉션**: 에이전트가 잘못된 경로로 가면 분석 중간에 중단하고 방향 수정 가능
- **명확화 질문**: 지시가 불명확하거나 불완전할 때 **능동적으로 명확화 질문**
- **합리적 기본값**: 응답이 없으면 진행을 위한 합리적 기본값 적용 (예: 날짜 범위 미지정 시 최근 7일 또는 30일 가정)

### Workflows (워크플로우)

출시 후 사용자들이 **일상적인 반복 작업을 위해 동일한 분석을 자주 실행**하는 것을 관찰했습니다. 이를 간소화하기 위해:

- **워크플로우**는 반복 분석을 재사용 가능한 지시 세트로 패키징
- 예: 주간 비즈니스 보고서, 테이블 검증
- 컨텍스트와 모범 사례를 한 번 인코딩하여 일관된 결과 보장

## 품질 보호: Evals

항상 켜져 있고 진화하는 에이전트를 구축하면 품질이 개선되는 만큼 쉽게 저하될 수 있습니다. 신뢰를 깨지 않고 능력을 확장하는 유일한 방법은 **체계적인 평가**입니다.

### OpenAI Evals API 활용

- **큐레이션된 Q&A 쌍**: 중요한 메트릭이나 분석 패턴을 타겟팅하는 질문
- **"골든" SQL 쿼리**: 예상 결과를 생성하는 수동 작성 쿼리
- **비교**: 생성된 SQL을 실행하고 출력을 예상 SQL 결과와 비교

Evals는 **개발 중 지속적으로 실행**되어 회귀를 조기에 포착하고 에이전트 능력 확장 시 자신감 있게 반복할 수 있습니다.

## 보안

에이전트는 **OpenAI의 기존 보안 및 접근 제어 모델에 연결**됩니다:

- **순수 인터페이스 레이어**: 기존 권한과 가드레일 상속 및 적용
- **패스스루 접근**: 사용자는 이미 권한이 있는 테이블만 쿼리 가능
- **투명성**: 가정과 실행 단계를 각 답변과 함께 요약
- **검증 가능**: 쿼리 실행 시 기본 결과에 직접 링크하여 원시 데이터 검사 및 모든 단계 검증 가능

## 교훈

### Lesson #1: Less is More

초기에는 전체 도구 세트를 에이전트에 노출했지만, 겹치는 기능으로 인해 문제가 발생했습니다. **중복 제거 및 도구 호출 통합**으로 모호성을 줄이고 신뢰성을 개선했습니다.

### Lesson #2: Guide the Goal, Not the Path

매우 규범적인 프롬프팅이 결과를 저하시킨다는 것을 발견했습니다. **상위 수준 가이던스**로 전환하고 GPT-5의 추론에 의존하여 적절한 실행 경로를 선택하도록 하니 에이전트가 더 강건해지고 더 나은 결과를 생성했습니다.

### Lesson #3: Meaning Lives in Code

스키마와 쿼리 히스토리는 테이블의 형태와 사용을 설명하지만, **진정한 의미는 테이블을 생성하는 코드에 있습니다**. 파이프라인 로직은 가정, 신선도 보장, 비즈니스 의도를 포착합니다. **Codex로 코드베이스를 크롤링**함으로써 에이전트는 데이터셋이 실제로 어떻게 구성되는지 이해하고 "여기에 무엇이 있는가"와 "언제 사용할 수 있는가"를 훨씬 더 정확하게 답변할 수 있습니다.

## 기술 스택

OpenAI는 에이전트 구축에 다음을 사용했습니다 (모든 개발자에게 제공되는 동일한 도구):

- **[Codex](/index/introducing-codex/)**: 코드베이스 분석 및 테이블 의미 이해
- **[GPT-5](/index/introducing-gpt-5-2/)**: 주력 추론 모델
- **[Evals API](https://platform.openai.com/docs/guides/evals)**: 품질 평가 및 회귀 감지
- **[Embeddings API](https://platform.openai.com/docs/guides/embeddings)**: 컨텍스트 임베딩 및 검색

---

### 왜 개발자가 관심 가져야 할까

OpenAI 내부 도구지만, **아키텍처 패턴은 일반 웹 앱에도 적용 가능**합니다. 특히:

- **React 대시보드 + 복잡한 SQL**: 어드민 패널, 분석 도구에서 "올바른 테이블 찾기" 문제는 익숙함
- **Embeddings API + RAG**: 우리도 쓸 수 있는 오픈 API. 메타데이터를 임베딩하고 유사도 검색하는 방식은 범용 패턴
- **자가 학습 루프**: GPT-4/5의 추론 능력을 활용해 "쿼리 실행 → 에러 분석 → 재시도" 플로우를 구현 가능

### 프론트엔드 활용: 분석 대시보드 자동화

현재 많은 앱이 **Recharts + 하드코딩된 SQL 쿼리** 조합을 사용합니다. 이 구조에서:

```typescript
// 현재: 하드코딩된 쿼리
const dailyActiveUsers = await db.query(`
  SELECT date, COUNT(DISTINCT user_id)
  FROM events WHERE event_type = 'login'
  GROUP BY date
`);

// AI 에이전트 적용 후: 자연어 쿼리
const result = await analyticsAgent.ask(
  "지난 7일간 일별 활성 사용자 수를 보여줘. iOS와 Android를 분리해줘."
);
```

**구현 시 참고할 패턴:**

- Embeddings API로 테이블 스키마 + 과거 쿼리 임베딩
- 사용자 질문을 벡터 검색으로 관련 컨텍스트 수집
- GPT-4/5에게 SQL 생성 + 실행 + 결과 해석 요청

### 백엔드 활용: 데이터베이스 쿼리 최적화

**"어떤 테이블을 조인해야 하나?"** 문제는 레거시 DB에서 흔합니다:

- 70,000개 테이블은 아니어도, 수백 개의 테이블 + 유사한 이름 (users, user_profiles, user_metadata...)
- Codex로 **테이블 생성 코드 분석** → "이 필드는 왜 nullable인가?" 같은 맥락 파악
- OpenAI의 "Layer #3: Codex 보강" 전략을 우리 ORM 마이그레이션 코드에 적용 가능

### 실제 적용 가능성

| 요구사항         | 현실성                          | 비용                     |
| ---------------- | ------------------------------- | ------------------------ |
| Embeddings API   | ✅ 즉시 가능                    | $0.00013/1K tokens       |
| GPT-4/5 SQL 생성 | ✅ 즉시 가능                    | $2.50/1M tokens (GPT-4o) |
| Codex 코드 분석  | ✅ 오픈 소스 대안 (tree-sitter) | 무료                     |
| RAG 파이프라인   | ✅ Pinecone/Weaviate            | 무료 티어 가능           |

**hands-on 여부: 아직 구현 안 함**  
개념적으로는 명확하지만, 프로덕션 환경에서 "자가 학습 SQL 에이전트"를 안전하게 운영하려면:

- SQL 실행 전 dry-run 검증
- 파괴적 쿼리 차단 (DELETE, DROP)
- 결과 크기 제한 (timeout, row limit)

### 한 줄 요약

OpenAI의 데이터 에이전트는 **"Embeddings API + GPT-5 + RAG"의 실전 응용 사례**. 우리 앱 규모에서도 분석 쿼리 자동화, 스키마 검색, 쿼리 최적화에 즉시 적용 가능한 패턴.

---

**출처**: [OpenAI - Inside OpenAI's in-house data agent](https://openai.com/index/inside-our-in-house-data-agent)
